{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Caltech256_Resnet50_DataAugmentation+EncoderDecoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhyan1999/DL_ML/blob/master/Caltech256_Resnet50_DataAugmentation%2BEncoderDecoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbcWWCZixGLo"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F59AQW6akHGr",
        "outputId": "10d689aa-aec7-4516-8af9-8d481e3f6bd8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtrkBBLOkG7M",
        "outputId": "2ad25397-df9d-4eb0-e9cf-acdf5323f92b"
      },
      "source": [
        "!pip install patool pyunpack\n",
        "import pyunpack\n",
        "pyunpack.Archive(\"/content/drive/MyDrive/Caltech256.rar\").extractall(\"/content/dataset\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.8MB/s \n",
            "\u001b[?25hCollecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/b0/8ef4b1d8be02448d164c52466530059d7f57218655d21309a0c4236d7454/entrypoint2-0.2.4-py3-none-any.whl\n",
            "Installing collected packages: patool, easyprocess, entrypoint2, pyunpack\n",
            "Successfully installed easyprocess-0.3 entrypoint2-0.2.4 patool-1.12 pyunpack-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zVg9pQCUVjO"
      },
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "os.mkdir(\"caltech_test\") \n",
        "\n",
        "for cat in os.listdir(\"/content/dataset/Caltech256/\"):\n",
        "  imgs = os.listdir(\"/content/dataset/Caltech256/\"+cat) \n",
        "  test_imgs = imgs[30:len(imgs)]\n",
        "  for t_img in test_imgs: \n",
        "    os.rename(\"/content/dataset/Caltech256/\"+cat+\"/\"+t_img, \"caltech_test/\"+cat+\"/\"+t_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf363T2k3Ac6"
      },
      "source": [
        "def fixed_generator(generator):\n",
        "    for batch in generator:\n",
        "        yield (batch, batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmJGh0GGWkXk"
      },
      "source": [
        "**Preparing data for feature extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdgslrt8UYvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1447bb27-9c23-4ca6-c766-3cf6fe9ea238"
      },
      "source": [
        "# import cv2\n",
        "from keras.applications.resnet50 import preprocess_input \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_gen_autoencoder = ImageDataGenerator(rescale=1./255) \n",
        "train_flow = train_gen_autoencoder.flow_from_directory(\"/content/dataset/Caltech256/\", target_size=(256, 256), batch_size=60,class_mode=None)\n",
        "valid_flow = train_gen_autoencoder.flow_from_directory(\"caltech_test/\", target_size=(256, 256), batch_size=60,class_mode=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7680 images belonging to 256 classes.\n",
            "Found 22100 images belonging to 256 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k72YmIkNXMyZ"
      },
      "source": [
        "**Importing necessary library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMnbi4f3UjCC"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky23DnIzUjoh"
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# Encoder layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2), padding='same') )\n",
        "\n",
        "# Decoder Layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.UpSampling2D((2, 2)) )\n",
        "\n",
        "model.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same') )\n",
        "\n",
        "model.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48S4JkL4UnbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f325c56b-fd9b-442b-9df2-960b60d4a2d9"
      },
      "source": [
        "model.fit_generator(fixed_generator(train_flow), epochs=5,steps_per_epoch=7710//128, validation_steps=22897//128,validation_data = fixed_generator(valid_flow) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60/60 [==============================] - 48s 789ms/step - loss: 0.7315 - val_loss: 0.7285\n",
            "Epoch 2/5\n",
            "60/60 [==============================] - 49s 834ms/step - loss: 0.7280 - val_loss: 0.7255\n",
            "Epoch 3/5\n",
            "60/60 [==============================] - 47s 800ms/step - loss: 0.7251 - val_loss: 0.7223\n",
            "Epoch 4/5\n",
            "60/60 [==============================] - 49s 832ms/step - loss: 0.7219 - val_loss: 0.7199\n",
            "Epoch 5/5\n",
            "60/60 [==============================] - 48s 820ms/step - loss: 0.7192 - val_loss: 0.7168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f093043ff90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzOyFuf1UwWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341515b7-295f-4fc2-bda1-aeead4bd5c8c"
      },
      "source": [
        "from keras.applications.resnet50 import preprocess_input # make sure to match original model's preprocessing function\n",
        "\n",
        "train_gen = ImageDataGenerator(validation_split=0.2, preprocessing_function=preprocess_input)\n",
        "train_flow = train_gen.flow_from_directory(\"/content/dataset/Caltech256/\", target_size=(256, 256), batch_size=130, subset=\"training\")\n",
        "valid_flow = train_gen.flow_from_directory(\"/content/dataset/Caltech256/\", target_size=(256, 256), batch_size=130, subset=\"validation\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6144 images belonging to 256 classes.\n",
            "Found 1536 images belonging to 256 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2iqp6RMU1Xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e635ad2f-5c18-46d5-850e-f5b09a0a8c19"
      },
      "source": [
        "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_flow = test_gen.flow_from_directory(\"caltech_test\", target_size=(256, 256), batch_size=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22100 images belonging to 256 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_frC2j9U9vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a9d5cd-1fb2-4845-e351-b07f4396d720"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import GlobalAveragePooling2D, BatchNormalization, Dropout, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "res = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3)) \n",
        "\n",
        "for layer in res.layers: \n",
        "  layer.trainable = False\n",
        "\n",
        "x = res.output \n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='softmax')(x)\n",
        "\n",
        "model = Model(res.input, x) \n",
        "opt = tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False,\n",
        "    name=\"RMSprop\"\n",
        ")\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2048)         8192        global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          1049088     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 24,778,368\n",
            "Trainable params: 1,185,536\n",
            "Non-trainable params: 23,592,832\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDC2Y9uFVA4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881250c9-22a0-4d54-b0bd-3f6f9788133f"
      },
      "source": [
        "history = model.fit_generator(train_flow, epochs=100, validation_data=valid_flow) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "48/48 [==============================] - 34s 640ms/step - loss: 5.2065 - accuracy: 0.1025 - val_loss: 2.4864 - val_accuracy: 0.6055\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 30s 613ms/step - loss: 2.2103 - accuracy: 0.5257 - val_loss: 1.5412 - val_accuracy: 0.7233\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 30s 613ms/step - loss: 1.4250 - accuracy: 0.6920 - val_loss: 1.1940 - val_accuracy: 0.7493\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 29s 604ms/step - loss: 1.0002 - accuracy: 0.7736 - val_loss: 1.0439 - val_accuracy: 0.7630\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 29s 597ms/step - loss: 0.7536 - accuracy: 0.8310 - val_loss: 0.9538 - val_accuracy: 0.7708\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 29s 606ms/step - loss: 0.6335 - accuracy: 0.8643 - val_loss: 0.8896 - val_accuracy: 0.7845\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 29s 599ms/step - loss: 0.4936 - accuracy: 0.8890 - val_loss: 0.8559 - val_accuracy: 0.7975\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 29s 600ms/step - loss: 0.3942 - accuracy: 0.9140 - val_loss: 0.8405 - val_accuracy: 0.7904\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 29s 599ms/step - loss: 0.3556 - accuracy: 0.9226 - val_loss: 0.8351 - val_accuracy: 0.7923\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 29s 612ms/step - loss: 0.3027 - accuracy: 0.9377 - val_loss: 0.8335 - val_accuracy: 0.7891\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 29s 611ms/step - loss: 0.2707 - accuracy: 0.9406 - val_loss: 0.8266 - val_accuracy: 0.7852\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 29s 612ms/step - loss: 0.2284 - accuracy: 0.9483 - val_loss: 0.8185 - val_accuracy: 0.7910\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 29s 610ms/step - loss: 0.2073 - accuracy: 0.9623 - val_loss: 0.8128 - val_accuracy: 0.7904\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 29s 608ms/step - loss: 0.1875 - accuracy: 0.9571 - val_loss: 0.8131 - val_accuracy: 0.7969\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 29s 607ms/step - loss: 0.1700 - accuracy: 0.9670 - val_loss: 0.8233 - val_accuracy: 0.7904\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 29s 607ms/step - loss: 0.1542 - accuracy: 0.9665 - val_loss: 0.8175 - val_accuracy: 0.7923\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 29s 613ms/step - loss: 0.1502 - accuracy: 0.9662 - val_loss: 0.8262 - val_accuracy: 0.7917\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 30s 615ms/step - loss: 0.1210 - accuracy: 0.9774 - val_loss: 0.8214 - val_accuracy: 0.7930\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 29s 607ms/step - loss: 0.1307 - accuracy: 0.9716 - val_loss: 0.8270 - val_accuracy: 0.7956\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 30s 617ms/step - loss: 0.1201 - accuracy: 0.9742 - val_loss: 0.8228 - val_accuracy: 0.7949\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.1122 - accuracy: 0.9761 - val_loss: 0.8219 - val_accuracy: 0.7995\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 29s 610ms/step - loss: 0.1007 - accuracy: 0.9800 - val_loss: 0.8235 - val_accuracy: 0.7930\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.1005 - accuracy: 0.9769 - val_loss: 0.8278 - val_accuracy: 0.7865\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0930 - accuracy: 0.9828 - val_loss: 0.8217 - val_accuracy: 0.7858\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0862 - accuracy: 0.9846 - val_loss: 0.8347 - val_accuracy: 0.7943\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0901 - accuracy: 0.9782 - val_loss: 0.8619 - val_accuracy: 0.7910\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 29s 610ms/step - loss: 0.0799 - accuracy: 0.9847 - val_loss: 0.8553 - val_accuracy: 0.7852\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0782 - accuracy: 0.9829 - val_loss: 0.8577 - val_accuracy: 0.7904\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 29s 606ms/step - loss: 0.0842 - accuracy: 0.9807 - val_loss: 0.8477 - val_accuracy: 0.7910\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 29s 613ms/step - loss: 0.0758 - accuracy: 0.9854 - val_loss: 0.8489 - val_accuracy: 0.7956\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 29s 601ms/step - loss: 0.0763 - accuracy: 0.9828 - val_loss: 0.8589 - val_accuracy: 0.7943\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0706 - accuracy: 0.9844 - val_loss: 0.8657 - val_accuracy: 0.7897\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 29s 598ms/step - loss: 0.0664 - accuracy: 0.9864 - val_loss: 0.8666 - val_accuracy: 0.7845\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 29s 599ms/step - loss: 0.0649 - accuracy: 0.9854 - val_loss: 0.8617 - val_accuracy: 0.7897\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 29s 607ms/step - loss: 0.0637 - accuracy: 0.9867 - val_loss: 0.8571 - val_accuracy: 0.7897\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0638 - accuracy: 0.9872 - val_loss: 0.8727 - val_accuracy: 0.7975\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0641 - accuracy: 0.9845 - val_loss: 0.8613 - val_accuracy: 0.7904\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 29s 611ms/step - loss: 0.0628 - accuracy: 0.9833 - val_loss: 0.8695 - val_accuracy: 0.7988\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 30s 615ms/step - loss: 0.0518 - accuracy: 0.9889 - val_loss: 0.8645 - val_accuracy: 0.7897\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 29s 610ms/step - loss: 0.0592 - accuracy: 0.9862 - val_loss: 0.8656 - val_accuracy: 0.7871\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 29s 611ms/step - loss: 0.0502 - accuracy: 0.9894 - val_loss: 0.8701 - val_accuracy: 0.7923\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0499 - accuracy: 0.9903 - val_loss: 0.8603 - val_accuracy: 0.7897\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 29s 600ms/step - loss: 0.0518 - accuracy: 0.9883 - val_loss: 0.8662 - val_accuracy: 0.7962\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 30s 616ms/step - loss: 0.0502 - accuracy: 0.9893 - val_loss: 0.8661 - val_accuracy: 0.7988\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0538 - accuracy: 0.9868 - val_loss: 0.8695 - val_accuracy: 0.7910\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 29s 610ms/step - loss: 0.0493 - accuracy: 0.9894 - val_loss: 0.8828 - val_accuracy: 0.7852\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0497 - accuracy: 0.9894 - val_loss: 0.8890 - val_accuracy: 0.7884\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 29s 606ms/step - loss: 0.0462 - accuracy: 0.9915 - val_loss: 0.8847 - val_accuracy: 0.7878\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0560 - accuracy: 0.9862 - val_loss: 0.8812 - val_accuracy: 0.7910\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0432 - accuracy: 0.9909 - val_loss: 0.8799 - val_accuracy: 0.7891\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0479 - accuracy: 0.9908 - val_loss: 0.8715 - val_accuracy: 0.7897\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 29s 601ms/step - loss: 0.0502 - accuracy: 0.9863 - val_loss: 0.8604 - val_accuracy: 0.7871\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0453 - accuracy: 0.9913 - val_loss: 0.8694 - val_accuracy: 0.7832\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 29s 600ms/step - loss: 0.0435 - accuracy: 0.9902 - val_loss: 0.8670 - val_accuracy: 0.7910\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 29s 596ms/step - loss: 0.0399 - accuracy: 0.9909 - val_loss: 0.8680 - val_accuracy: 0.7949\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0434 - accuracy: 0.9929 - val_loss: 0.8730 - val_accuracy: 0.7982\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 29s 604ms/step - loss: 0.0436 - accuracy: 0.9917 - val_loss: 0.8832 - val_accuracy: 0.7930\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 29s 619ms/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 0.8830 - val_accuracy: 0.7891\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 29s 607ms/step - loss: 0.0361 - accuracy: 0.9921 - val_loss: 0.8748 - val_accuracy: 0.7891\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 29s 603ms/step - loss: 0.0389 - accuracy: 0.9915 - val_loss: 0.8848 - val_accuracy: 0.7878\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 29s 611ms/step - loss: 0.0421 - accuracy: 0.9899 - val_loss: 0.8798 - val_accuracy: 0.7897\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.8780 - val_accuracy: 0.7884\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 29s 615ms/step - loss: 0.0389 - accuracy: 0.9905 - val_loss: 0.8894 - val_accuracy: 0.7871\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0397 - accuracy: 0.9923 - val_loss: 0.8944 - val_accuracy: 0.7943\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 29s 613ms/step - loss: 0.0399 - accuracy: 0.9893 - val_loss: 0.8802 - val_accuracy: 0.7930\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 29s 601ms/step - loss: 0.0421 - accuracy: 0.9893 - val_loss: 0.8767 - val_accuracy: 0.7871\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 29s 595ms/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 0.8869 - val_accuracy: 0.7904\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 29s 604ms/step - loss: 0.0335 - accuracy: 0.9909 - val_loss: 0.8856 - val_accuracy: 0.7930\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 29s 603ms/step - loss: 0.0403 - accuracy: 0.9906 - val_loss: 0.8929 - val_accuracy: 0.7904\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 29s 610ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.8988 - val_accuracy: 0.7832\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0357 - accuracy: 0.9909 - val_loss: 0.8878 - val_accuracy: 0.7943\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 29s 611ms/step - loss: 0.0329 - accuracy: 0.9917 - val_loss: 0.8821 - val_accuracy: 0.7962\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.8836 - val_accuracy: 0.7969\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 29s 608ms/step - loss: 0.0326 - accuracy: 0.9932 - val_loss: 0.8829 - val_accuracy: 0.7988\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 29s 610ms/step - loss: 0.0423 - accuracy: 0.9896 - val_loss: 0.8921 - val_accuracy: 0.8053\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0345 - accuracy: 0.9913 - val_loss: 0.8991 - val_accuracy: 0.8027\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 29s 608ms/step - loss: 0.0325 - accuracy: 0.9934 - val_loss: 0.8968 - val_accuracy: 0.7936\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0405 - accuracy: 0.9897 - val_loss: 0.8816 - val_accuracy: 0.7969\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 29s 603ms/step - loss: 0.0338 - accuracy: 0.9932 - val_loss: 0.8875 - val_accuracy: 0.8008\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 29s 601ms/step - loss: 0.0339 - accuracy: 0.9929 - val_loss: 0.8971 - val_accuracy: 0.7917\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 29s 600ms/step - loss: 0.0282 - accuracy: 0.9951 - val_loss: 0.8935 - val_accuracy: 0.7897\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 29s 605ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 0.8804 - val_accuracy: 0.7982\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 29s 606ms/step - loss: 0.0345 - accuracy: 0.9922 - val_loss: 0.8815 - val_accuracy: 0.7982\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 29s 613ms/step - loss: 0.0375 - accuracy: 0.9927 - val_loss: 0.8684 - val_accuracy: 0.7988\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0343 - accuracy: 0.9926 - val_loss: 0.8974 - val_accuracy: 0.7936\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0319 - accuracy: 0.9911 - val_loss: 0.8967 - val_accuracy: 0.7969\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 29s 607ms/step - loss: 0.0300 - accuracy: 0.9922 - val_loss: 0.9056 - val_accuracy: 0.7910\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 29s 601ms/step - loss: 0.0357 - accuracy: 0.9908 - val_loss: 0.9108 - val_accuracy: 0.7897\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 29s 594ms/step - loss: 0.0308 - accuracy: 0.9936 - val_loss: 0.9082 - val_accuracy: 0.7910\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 29s 607ms/step - loss: 0.0371 - accuracy: 0.9897 - val_loss: 0.9034 - val_accuracy: 0.7871\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0277 - accuracy: 0.9953 - val_loss: 0.9142 - val_accuracy: 0.7878\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 29s 601ms/step - loss: 0.0323 - accuracy: 0.9927 - val_loss: 0.9047 - val_accuracy: 0.7949\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 29s 600ms/step - loss: 0.0312 - accuracy: 0.9920 - val_loss: 0.9006 - val_accuracy: 0.7923\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0289 - accuracy: 0.9925 - val_loss: 0.8941 - val_accuracy: 0.7943\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 29s 608ms/step - loss: 0.0293 - accuracy: 0.9940 - val_loss: 0.8993 - val_accuracy: 0.7884\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 29s 601ms/step - loss: 0.0295 - accuracy: 0.9944 - val_loss: 0.8875 - val_accuracy: 0.7936\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 29s 609ms/step - loss: 0.0311 - accuracy: 0.9927 - val_loss: 0.8948 - val_accuracy: 0.7910\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 29s 610ms/step - loss: 0.0287 - accuracy: 0.9919 - val_loss: 0.8862 - val_accuracy: 0.7962\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 29s 608ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.8947 - val_accuracy: 0.7982\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 0.0225 - accuracy: 0.9947 - val_loss: 0.8843 - val_accuracy: 0.8001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rY7E-JjVP2Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "ac915392-9df3-44ca-8c2c-0270457efcd8"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"performance_caltech256.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
